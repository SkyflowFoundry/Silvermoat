name: E2E Tests with Ephemeral Stack

on:
  pull_request:
    branches: [main]
    paths:
      - 'infra/**'
      - 'ui/**'
      - 'tests/**'
      - 'scripts/**'
      - '.github/workflows/**'
  workflow_dispatch:
    inputs:
      pr_number:
        description: 'PR number for stack naming (optional)'
        required: false

permissions:
  id-token: write
  contents: read
  pull-requests: write

jobs:
  setup-stack:
    runs-on: ubuntu-latest
    timeout-minutes: 20

    outputs:
      stack_name: ${{ steps.stack-name.outputs.stack_name }}
      api_url: ${{ steps.stack-outputs.outputs.api_url }}
      web_url: ${{ steps.stack-outputs.outputs.web_url }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup environment
        uses: ./.github/actions/setup-env

      - name: Install dependencies
        uses: ./.github/actions/install-deps

      - name: Run JavaScript unit tests
        run: |
          cd ui
          npm test -- --run

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: us-east-1

      - name: Determine test stack name
        id: stack-name
        run: |
          if [ -n "${{ github.event.pull_request.number }}" ]; then
            STACK_NAME="silvermoat-test-pr-${{ github.event.pull_request.number }}"
          elif [ -n "${{ inputs.pr_number }}" ]; then
            STACK_NAME="silvermoat-test-pr-${{ inputs.pr_number }}"
          else
            STACK_NAME="silvermoat-test-${{ github.run_id }}"
          fi
          echo "stack_name=${STACK_NAME}" >> $GITHUB_OUTPUT
          echo "Test stack name: ${STACK_NAME}"

      - name: Deploy test stack
        env:
          STACK_NAME: ${{ steps.stack-name.outputs.stack_name }}
          APP_NAME: silvermoat-test
          STAGE_NAME: test
          UI_SEEDING_MODE: external
          CREATE_CLOUDFRONT: false
          DOMAIN_NAME: ""
        run: |
          echo "Deploying test stack: ${STACK_NAME}"
          chmod +x scripts/deploy-stack.sh
          ./scripts/deploy-stack.sh

      - name: Wait for stack deployment
        run: |
          echo "Waiting for stack deployment to complete..."
          aws cloudformation wait stack-create-complete \
            --stack-name ${{ steps.stack-name.outputs.stack_name }} \
            --region us-east-1 || \
          aws cloudformation wait stack-update-complete \
            --stack-name ${{ steps.stack-name.outputs.stack_name }} \
            --region us-east-1

      - name: Build and deploy React UI
        env:
          STACK_NAME: ${{ steps.stack-name.outputs.stack_name }}
        run: |
          echo "Building and deploying React UI..."
          chmod +x scripts/deploy-ui.sh
          ./scripts/deploy-ui.sh

      - name: Get stack outputs
        id: stack-outputs
        run: |
          STACK_NAME="${{ steps.stack-name.outputs.stack_name }}"

          # Get all outputs as JSON
          OUTPUTS=$(aws cloudformation describe-stacks \
            --stack-name "${STACK_NAME}" \
            --query 'Stacks[0].Outputs' \
            --output json)

          # Extract specific outputs
          API_URL=$(echo "$OUTPUTS" | jq -r '.[] | select(.OutputKey=="ApiBaseUrl") | .OutputValue')

          # Try CloudFrontUrl first (production), fall back to WebUrl (test stacks)
          WEB_URL=$(echo "$OUTPUTS" | jq -r '.[] | select(.OutputKey=="CloudFrontUrl") | .OutputValue')
          if [ -z "$WEB_URL" ] || [ "$WEB_URL" == "null" ]; then
            WEB_URL=$(echo "$OUTPUTS" | jq -r '.[] | select(.OutputKey=="WebUrl") | .OutputValue')
          fi

          echo "api_url=${API_URL}" >> $GITHUB_OUTPUT
          echo "web_url=${WEB_URL}" >> $GITHUB_OUTPUT

          echo "API URL: ${API_URL}"
          echo "Web URL: ${WEB_URL}"

  test-suite:
    needs: setup-stack
    runs-on: ubuntu-latest
    timeout-minutes: 15

    strategy:
      fail-fast: false
      matrix:
        test-type: [smoke, api, e2e]
        include:
          - test-type: smoke
            test-dir: smoke
            pytest-mark: smoke
            needs-chrome: false
          - test-type: api
            test-dir: api
            pytest-mark: api
            needs-chrome: false
          - test-type: e2e
            test-dir: e2e
            pytest-mark: smoke
            needs-chrome: true

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup environment
        uses: ./.github/actions/setup-env

      - name: Install Python dependencies
        run: pip install -r requirements-test.txt

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: us-east-1

      - name: Install Chrome and ChromeDriver
        if: matrix.needs-chrome
        uses: browser-actions/setup-chrome@v1
        with:
          chrome-version: stable

      - name: Run ${{ matrix.test-type }} tests
        id: test-run
        continue-on-error: true
        env:
          STACK_NAME: ${{ needs.setup-stack.outputs.stack_name }}
          SILVERMOAT_API_URL: ${{ needs.setup-stack.outputs.api_url }}
          SILVERMOAT_URL: ${{ needs.setup-stack.outputs.web_url }}
          HEADLESS: '1'
        run: |
          set -o pipefail
          echo "Running ${{ matrix.test-type }} tests..."
          cd tests/${{ matrix.test-dir }}
          pytest -v -m ${{ matrix.pytest-mark }} --tb=short 2>&1 | tee ../../${{ matrix.test-type }}-tests-output.txt

      - name: Upload test output
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.test-type }}-test-output
          path: ${{ matrix.test-type }}-tests-output.txt
          retention-days: 7

      - name: Check test outcome
        if: always()
        run: |
          if [ "${{ steps.test-run.outcome }}" = "failure" ]; then
            echo "${{ matrix.test-type }} tests failed"
            exit 1
          fi

  analyze-results:
    needs: test-suite
    if: always()
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all test outputs
        uses: actions/download-artifact@v4
        with:
          path: test-outputs

      - name: Analyze test results with Claude
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY_GITHUB_ACTIONS }}
        run: |
          echo "Analyzing test results with Claude..."

          # Verify API key is set
          if [ -z "$ANTHROPIC_API_KEY" ]; then
            echo "ERROR: ANTHROPIC_API_KEY_GITHUB_ACTIONS secret is not set"
            echo "API analysis skipped (no API key). Using fallback message." > test-analysis.md
            exit 0
          fi

          # Collect test outputs (escape for JSON, limit to 2000 lines each)
          SMOKE_OUTPUT=$(cat test-outputs/smoke-test-output/smoke-tests-output.txt 2>/dev/null | head -2000 | jq -Rs . || echo '"No output captured"')
          API_OUTPUT=$(cat test-outputs/api-test-output/api-tests-output.txt 2>/dev/null | head -2000 | jq -Rs . || echo '"No output captured"')
          E2E_OUTPUT=$(cat test-outputs/e2e-test-output/e2e-tests-output.txt 2>/dev/null | head -2000 | jq -Rs . || echo '"No output captured"')

          # Determine outcomes from job results (will be set in check-results job)
          SMOKE_OUTCOME="${{ needs.test-suite.result }}"
          API_OUTCOME="${{ needs.test-suite.result }}"
          E2E_OUTCOME="${{ needs.test-suite.result }}"

          # Build JSON request with proper escaping
          jq -n \
            --arg smoke_outcome "$SMOKE_OUTCOME" \
            --arg api_outcome "$API_OUTCOME" \
            --arg e2e_outcome "$E2E_OUTCOME" \
            --argjson smoke_output "$SMOKE_OUTPUT" \
            --argjson api_output "$API_OUTPUT" \
            --argjson e2e_output "$E2E_OUTPUT" \
            '{
              "model": "claude-sonnet-4-5",
              "max_tokens": 4096,
              "messages": [{
                "role": "user",
                "content": "You are analyzing test results from an E2E test suite for the Silvermoat insurance MVP application. Review the test outputs below and generate a concise PR comment summarizing:\n\n1. Overall status (‚úÖ passed / ‚ö†Ô∏è partial / ‚ùå failed)\n2. Key findings for each test suite\n3. Critical failures that need immediate attention\n4. Recommendations for fixes (if failures exist)\n\nFormat as GitHub-flavored markdown. Be specific about which tests failed and why. Limit to 500 words.\n\n## Test Outcomes\n- Smoke tests: \($smoke_outcome)\n- API tests: \($api_outcome)\n- E2E tests: \($e2e_outcome)\n\n## Deployment Smoke Tests\n```\n\($smoke_output)\n```\n\n## API Contract Tests\n```\n\($api_output)\n```\n\n## E2E Smoke Tests\n```\n\($e2e_output)\n```"
              }]
            }' > analysis-request.json

          # Call Claude API (60s timeout for analysis)
          set +e  # Don't exit on curl error
          curl -s --max-time 60 -o analysis-response.json -w "%{http_code}" \
            https://api.anthropic.com/v1/messages \
            -H "content-type: application/json" \
            -H "x-api-key: $ANTHROPIC_API_KEY" \
            -H "anthropic-version: 2023-06-01" \
            -d @analysis-request.json > http_code.txt
          CURL_EXIT=$?
          HTTP_CODE=$(cat http_code.txt 2>/dev/null || echo "000")
          set -e  # Re-enable exit on error

          echo "Curl exit code: $CURL_EXIT"
          echo "API response code: $HTTP_CODE"

          # Check for curl failures
          if [ $CURL_EXIT -ne 0 ]; then
            echo "Curl command failed with exit code $CURL_EXIT"
            if [ $CURL_EXIT -eq 28 ]; then
              echo "Timeout after 60 seconds"
            elif [ $CURL_EXIT -eq 6 ]; then
              echo "Could not resolve host api.anthropic.com"
            else
              echo "Connection or network error"
            fi
            echo "API analysis failed (connection error). Using fallback message." > test-analysis.md
            exit 0
          fi

          # Check HTTP response codes
          if [ "$HTTP_CODE" = "401" ]; then
            echo "Authentication failed - check ANTHROPIC_API_KEY secret"
            cat analysis-response.json 2>/dev/null || echo "No response body"
            echo "API analysis failed (authentication). Using fallback message." > test-analysis.md
            exit 0
          elif [ "$HTTP_CODE" = "429" ]; then
            echo "Rate limit exceeded"
            cat analysis-response.json 2>/dev/null || echo "No response body"
            echo "API analysis failed (rate limit). Using fallback message." > test-analysis.md
            exit 0
          elif [ "$HTTP_CODE" != "200" ]; then
            echo "API request failed with HTTP code $HTTP_CODE"
            cat analysis-response.json 2>/dev/null || echo "No response body"
            echo "API analysis failed (HTTP $HTTP_CODE). Using fallback message." > test-analysis.md
            exit 0
          fi

          # Extract the analysis
          ANALYSIS=$(jq -r '.content[0].text // "Analysis extraction failed"' analysis-response.json)

          # Save for next step
          echo "$ANALYSIS" > test-analysis.md
          echo "Analysis complete!"

      - name: Upload analysis
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-analysis
          path: test-analysis.md
          retention-days: 7

  post-to-pr:
    needs: [setup-stack, analyze-results]
    if: always() && github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    timeout-minutes: 2

    steps:
      - name: Download analysis
        uses: actions/download-artifact@v4
        with:
          name: test-analysis

      - name: Post results to PR
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const prNumber = context.payload.pull_request.number;
            const runUrl = `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
            const stackName = '${{ needs.setup-stack.outputs.stack_name }}';

            // Read AI-generated analysis
            let analysis = "Test analysis not available";
            try {
              analysis = fs.readFileSync('test-analysis.md', 'utf8');
            } catch (error) {
              console.log('Could not read analysis file:', error);
              analysis = "‚ö†Ô∏è AI analysis failed. Check logs for details.";
            }

            const body = `## ü§ñ E2E Test Analysis

            **Test Stack:** \`${stackName}\`
            **Run:** [View Full Logs](${runUrl})

            ---

            ${analysis}

            ---

            <sub>Stack \`${stackName}\` is running and will be cleaned up when this PR is closed. Analysis generated by Claude Sonnet 4.</sub>
            `;

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber,
              body: body
            });

  check-results:
    needs: test-suite
    if: always()
    runs-on: ubuntu-latest
    timeout-minutes: 2

    steps:
      - name: Check test results
        run: |
          echo "Checking test suite results..."
          echo "Test suite job result: ${{ needs.test-suite.result }}"

          if [ "${{ needs.test-suite.result }}" = "failure" ]; then
            echo "One or more test suites failed"
            exit 1
          fi
          echo "All test suites passed"
